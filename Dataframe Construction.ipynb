{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pursuit_functions\n",
    "import pyarrow as pa\n",
    "\n",
    "pd.set_option('display.max_columns', 100)  # Show more columns (default is 20)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# TODO: \n",
    "# * normalize column names (i.e. sessFile -> dataDir)\n",
    "# * look into LP03_03_pursuitRoot.mat corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimize_pyarrow_dtypes(df):\n",
    "    \"\"\"\n",
    "    Optimizes PyArrow-backed dtypes in a DataFrame by selecting the smallest appropriate dtype\n",
    "    for each column based on value ranges.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame with PyArrow-backed dtypes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with optimized PyArrow-backed dtypes.\n",
    "    \"\"\"\n",
    "    optimized_dtypes = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            min_val, max_val = df[col].min(), df[col].max()\n",
    "\n",
    "            # Select the most efficient integer dtype\n",
    "            if min_val >= 0 and max_val <= 255:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.uint8())\n",
    "            elif min_val >= 0 and max_val <= 65535:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.uint16())\n",
    "            elif min_val >= -128 and max_val <= 127:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.int8())\n",
    "            elif min_val >= -32768 and max_val <= 32767:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.int16())\n",
    "            elif min_val >= -(2**31) and max_val <= (2**31 - 1):\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.int32())\n",
    "            else:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.int64())\n",
    "\n",
    "        elif pd.api.types.is_float_dtype(df[col]):\n",
    "            min_val, max_val = df[col].min(), df[col].max()\n",
    "\n",
    "            # Select the most efficient float dtype\n",
    "            if min_val >= -65504 and max_val <= 65504:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.float16())\n",
    "            elif min_val >= -(2**31) and max_val <= (2**31 - 1):\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.float32())\n",
    "            else:\n",
    "                optimized_dtypes[col] = pd.ArrowDtype(pa.float64())\n",
    "\n",
    "    # Convert DataFrame dtypes\n",
    "    return df.astype(optimized_dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load region files\n",
    "data_dir = Path(\"/Volumes/ASA_Lab/Data/Andy/nitzPurusitData\")\n",
    "#\"/Users/may/pursuitSessionFiles\")\n",
    "#data_dir = Path(\"/Volumes/ASA_Lab/Data/Xiaoxiao/ppcRscEVCPoster/pursuitSessionFiles\")\n",
    "region_directories = pursuit_functions.file_reader.load_region_files(data_dir, 'Rsc.mat')\n",
    "print(\"Extracted structures:\", region_directories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(region_directories['slRsc']['sessFile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in region_directories['slRsc'].keys():\n",
    "    print(f\"{key}: {type(region_directories['slRsc'][key])}, shape: {region_directories['slRsc'][key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 here is the trial block type\n",
    "# there is only one valid block type per outer row \n",
    "region_directories['slRsc']['blocks'][0][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in region_directories['slRsc']['spkTimes'][0]:\n",
    "#    print(f\"{x:.4}\")\n",
    "# when spikes were detected in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pursuit files\n",
    "data_dir = Path(\"/Volumes/ASA_Lab/Data/Andy/nitzPurusitData/Sessions\")\n",
    "#data_dir = Path(\"/Volumes/ASA_Lab/Data/Xiaoxiao/ppcRscEVCPoster/pursuitSessionFiles\")\n",
    "\n",
    "include_files = np.unique(region_directories['slRsc']['sessFile'])\n",
    "pursuit_session_files = pursuit_functions.file_reader.load_session_files(data_dir, include_files=include_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a variable to a region_directories file\n",
    "ca1_directory = pd.DataFrame(region_directories['ca1SL'])\n",
    "ca3_directory = pd.DataFrame(region_directories['ca3SL'])\n",
    "rsc_directory = pd.DataFrame(region_directories['rscSL'])\n",
    "\n",
    "#display first few rows of the dataframe\n",
    "ca1_directory.head()\n",
    "ca3_directory.head()\n",
    "rsc_directory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert extracted pursuit session data into dataframes\n",
    "pursuit_df = {\n",
    "    filename: pd.DataFrame(file_data).convert_dtypes(dtype_backend=\"pyarrow\")\n",
    "    for filename, file_data in pursuit_session_files.items()\n",
    "}\n",
    "\n",
    "#display first few rows of a dataframe for a specific pursuit file\n",
    "pursuit_df['KB20_09_pursuitRoot.mat'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract trial block indices for all 3 region directory dataframes\n",
    "\n",
    "def extract_trial_blocks(region_directory):\n",
    "    \"\"\"Extracts start and end indices for trial blocks and stores them as separate columns.\"\"\"\n",
    "\n",
    "    #ensure column names are clean\n",
    "    region_directory.columns = region_directory.columns.str.strip()\n",
    "\n",
    "    #determine the correct block column structure\n",
    "    has_blocks = \"blocks\" in region_directory.columns\n",
    "    has_separate_blocks = all(col in region_directory.columns for col in [\"feBlock\", \"pursuitBlock\", \"feBlock2\"])\n",
    "\n",
    "    if not has_blocks and not has_separate_blocks:\n",
    "        print(f\"Warning: No recognized block column found in {region_directory}. Skipping extraction.\")\n",
    "        return region_directory\n",
    "\n",
    "    #convert NumPy arrays to lists only if using separate columns (CA3)\n",
    "    if has_separate_blocks:\n",
    "        for col in [\"feBlock\", \"pursuitBlock\", \"feBlock2\"]:\n",
    "            region_directory[col] = region_directory[col].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "    # extract trial block start/end indices\n",
    "    if has_blocks:  # CA1 & RSC (Single \"blocks\" column)\n",
    "        region_directory[\"FE1_start\"] = region_directory[\"blocks\"].apply(lambda x: x[0][0])\n",
    "        region_directory[\"FE1_end\"] = region_directory[\"blocks\"].apply(lambda x: x[0][1])\n",
    "        region_directory[\"pursuit_start\"] = region_directory[\"blocks\"].apply(lambda x: x[1][0])\n",
    "        region_directory[\"pursuit_end\"] = region_directory[\"blocks\"].apply(lambda x: x[1][1])\n",
    "        region_directory[\"FE2_start\"] = region_directory[\"blocks\"].apply(lambda x: x[2][0])\n",
    "        region_directory[\"FE2_end\"] = region_directory[\"blocks\"].apply(lambda x: x[2][1])\n",
    "    elif has_separate_blocks:  # CA3 (Separate columns)\n",
    "        region_directory[\"FE1_start\"] = region_directory[\"feBlock\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        region_directory[\"FE1_end\"] = region_directory[\"feBlock\"].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        region_directory[\"pursuit_start\"] = region_directory[\"pursuitBlock\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        region_directory[\"pursuit_end\"] = region_directory[\"pursuitBlock\"].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        region_directory[\"FE2_start\"] = region_directory[\"feBlock2\"].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)\n",
    "        region_directory[\"FE2_end\"] = region_directory[\"feBlock2\"].apply(lambda x: x[1] if isinstance(x, list) and len(x) > 0 else None)\n",
    "\n",
    "    return region_directory\n",
    "\n",
    "# apply the function to all region dataframes\n",
    "ca1_directory = extract_trial_blocks(ca1_directory)\n",
    "ca3_directory = extract_trial_blocks(ca3_directory)\n",
    "rsc_directory = extract_trial_blocks(rsc_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ca3_directory.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the mega dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def clean_session_filename(file_path):\n",
    "    \"\"\"Extract and format the correct session file name from a directory path.\"\"\"\n",
    "    cleaned_name = os.path.basename(file_path).replace(\"\\\\\", \"_\")\n",
    "\n",
    "    return (\n",
    "        cleaned_name if cleaned_name.endswith(\"_pursuitRoot.mat\") \n",
    "        else cleaned_name + \"pursuitRoot.mat\"\n",
    "    )\n",
    "\n",
    "def process_row(row, session_col, pursuit_df, region_name):\n",
    "    \"\"\"Helper function to process each row and extract trial blocks.\"\"\"\n",
    "    sessFile = row[session_col]\n",
    "    if session_col == \"dataDir\":\n",
    "        sessFile = clean_session_filename(sessFile)\n",
    "\n",
    "    session_data = pursuit_df.get(sessFile)\n",
    "    if session_data is None:\n",
    "        print(f\"Warning: Session file {sessFile} not found in pursuit_df. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    blocks = {\n",
    "        \"FE1\": (row[\"FE1_start\"], row[\"FE1_end\"]),\n",
    "        \"pursuit\": (row[\"pursuit_start\"], row[\"pursuit_end\"]),\n",
    "        \"FE2\": (row[\"FE2_start\"], row[\"FE2_end\"])\n",
    "    }\n",
    "\n",
    "    \n",
    "    extracted_blocks = [\n",
    "        session_data.iloc[int(start): int(end) + 1].assign(\n",
    "            region=region_name, trial_block=trial_block, sessFile=sessFile\n",
    "        )\n",
    "        for trial_block, (start, end) in blocks.items()\n",
    "        if pd.notna(start) and pd.notna(end)\n",
    "    ]\n",
    "    return extracted_blocks\n",
    "\n",
    "def extract_and_slice_region_data(region_name, region_directory, pursuit_df):\n",
    "    \"\"\"Extract trial block indices and slice corresponding session files.\"\"\"\n",
    "    session_col = \"sessFile\" if \"sessFile\" in region_directory.columns else \"dataDir\"\n",
    "\n",
    "    extracted_data = [\n",
    "        block\n",
    "        for _, row in region_directory.iterrows()\n",
    "        for block in (process_row(row, session_col, pursuit_df, region_name) or [])\n",
    "    ]\n",
    "\n",
    "    if not extracted_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    new_cols = [\"region\", \"trial_block\", \"sessFile\"]\n",
    "    out = pd.concat(extracted_data, ignore_index=True).dropna(axis=1, how=\"all\").astype({'region': \"category\", 'trial_block': \"category\", 'sessFile': \"category\"})\n",
    "    existing_columns = [col for col in out.columns if col not in new_cols]\n",
    "    out = out[existing_columns + new_cols]\n",
    "    return optimize_pyarrow_dtypes(out)\n",
    "\n",
    "ca1_data = extract_and_slice_region_data(\"CA1\", ca1_directory, pursuit_df)\n",
    "ca3_data = extract_and_slice_region_data(\"CA3\", ca3_directory, pursuit_df)\n",
    "rsc_data = extract_and_slice_region_data(\"RSC\", rsc_directory, pursuit_df)\n",
    "# TODO: save to parquet file, maybe\n",
    "\n",
    "# Combine all regions into a single dataset\n",
    "all_regions_data = pd.concat([ca1_data, ca3_data, rsc_data], ignore_index=True)\n",
    "\n",
    "# Sort data\n",
    "all_regions_data = all_regions_data.sort_values(by=[\"sessFile\", \"region\", \"trial_block\"]).reset_index(drop=True)\n",
    "\n",
    "# Display the final dataset\n",
    "all_regions_data.head()\n",
    "\n",
    "#save dataframe to a parquet file\n",
    "all_regions_data.to_parquet(\"/Users/may/pursuit/ca1_ca3_rsc_pursuit_data.parquet\", engine=\"pyarrow\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions_data[(all_regions_data[\"region\"] == \"CA3\") & (all_regions_data[\"trial_block\"] == \"pursuit\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying pursuit, shortcut, and characteristic trials\n",
    "\n",
    "df = all_regions_data[(all_regions_data[\"region\"] == \"CA3\") & (all_regions_data[\"trial_block\"] == \"pursuit\")].copy()\n",
    "df[\"ratMoveDir\"] = df[\"ratMoveDir\"].astype(\"float64\")\n",
    "df[\"laserMoveDir\"] = df[\"laserMoveDir\"].astype(\"float64\")\n",
    "df[\"laserDist\"] = df[\"laserDist\"].astype(\"float64\")\n",
    "df[\"ratVel\"] = df[\"ratVel\"].astype(\"float64\")\n",
    "df[\"laserBearingMD\"] = df[\"laserBearingMD\"].astype(\"float64\")\n",
    "\n",
    "#identifying start of runs\n",
    "\n",
    "df[\"movement_alignment\"] = np.abs(df[\"ratMoveDir\"] - df[\"laserMoveDir\"])\n",
    "\n",
    "coherent_movement = (df[\"movement_alignment\"] < np.deg2rad(30)) & (df[\"ratVel\"] > 2) & (df[\"laserVel\"] >2)\n",
    "\n",
    "approaching_laser = df[\"laserDist\"].diff() < 0\n",
    "\n",
    "df[\"start_of_run\"] = coherent_movement & approaching_laser\n",
    "\n",
    "#identifying end of runs\n",
    "rat_reached_laser = df[\"laserDist\"] < 3 #i can change this threshold\n",
    "\n",
    "tracking_lost = df[\"laserDist\"].isna() | df[\"laserDist\"].diff().abs() > 50\n",
    "\n",
    "rat_stops = df[\"ratVel\"].diff() < -2 #looking for velocity drops\n",
    "\n",
    "df[\"end_of_run\"] = rat_reached_laser | tracking_lost | rat_stops\n",
    "\n",
    "#identifying trial types\n",
    "#compute median and variance of egocentric measures for each trial\n",
    "trial_stats = df.groupby(\"sessFile\")[[\"laserBearingMD\", \"laserDist\"]].agg([\"median\", \"std\"])\n",
    "trial_stats.columns = ['_'.join(col).strip() for col in trial_stats.columns]\n",
    "trial_stats = trial_stats.reset_index()\n",
    "df = df.merge(trial_stats, on=\"sessFile\", how=\"left\")\n",
    "\n",
    "#defining thresholds for trajectory types\n",
    "rt_threshold = trial_stats[\"laserBearingMD_std\"].quantile(0.30)\n",
    "ct_threshold = trial_stats[\"laserBearingMD_std\"].quantile(0.20)\n",
    "sc_threshold = trial_stats[\"laserDist_median\"].quantile(0.15)\n",
    "\n",
    "df[\"trial_type\"] = \"CT\"\n",
    "df.loc[df[\"laserBearingMD_std\"] > rt_threshold, \"trial_type\"] = \"RT\"\n",
    "df.loc[df[\"laserBearingMD_std\"] < ct_threshold, \"trial_type\"] = \"CT\"\n",
    "df.loc[df[\"laserDist_median\"] < sc_threshold, \"trial_type\"] = \"SC\"\n",
    "\n",
    "print(trial_stats.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram for laserBearingMD_std\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a histogram for laserBearingMD_std\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(trial_stats[\"laserBearingMD_std\"], bins=30, kde=True, color=\"blue\", alpha=0.6)\n",
    "\n",
    "# Overlay RT and CT thresholds as vertical lines\n",
    "plt.axvline(rt_threshold, color=\"red\", linestyle=\"dashed\", linewidth=2, label=f\"RT Threshold ({rt_threshold:.2f})\")\n",
    "plt.axvline(ct_threshold, color=\"green\", linestyle=\"dashed\", linewidth=2, label=f\"CT Threshold ({ct_threshold:.2f})\")\n",
    "\n",
    "plt.xlabel(\"laserBearingMD_std\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of laserBearingMD_std with RT/CT Thresholds\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a histogram for laserDist_median\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(trial_stats[\"laserDist_median\"], bins=30, kde=True, color=\"purple\", alpha=0.6)\n",
    "\n",
    "# Overlay Shortcut (SC) threshold\n",
    "plt.axvline(sc_threshold, color=\"orange\", linestyle=\"dashed\", linewidth=2, label=f\"SC Threshold ({sc_threshold:.2f})\")\n",
    "\n",
    "plt.xlabel(\"laserDist_median\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of laserDist_median with SC Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pseudorandom, characteristic, and shortcut trials\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get all session IDs where region == \"CA3\" and trial_block == \"pursuit\"\n",
    "session_ids = df[(df[\"region\"] == \"CA3\") & (df[\"trial_block\"] == \"pursuit\")][\"sessFile\"].unique()\n",
    "trial_types = [\"RT\", \"CT\", \"SC\"]  # Pseudorandom, Characteristic, Shortcut\n",
    "\n",
    "for session_id in session_ids:  # Loop through all sessions\n",
    "    plt.figure(figsize=(15, 5))  # Create a wide figure for side-by-side plots\n",
    "\n",
    "    for i, trial_type in enumerate(trial_types):  # Loop through RT, CT, SC\n",
    "        df_session = df[(df[\"sessFile\"] == session_id) & (df[\"trial_type\"] == trial_type)].copy()\n",
    "\n",
    "        # Skip if there are no trials of this type\n",
    "        if df_session.empty:\n",
    "            print(f\"No {trial_type} trials found for session {session_id}. Skipping {trial_type} plot.\")\n",
    "            continue\n",
    "\n",
    "        # Convert halffloat columns to float64\n",
    "        df_session[\"ratPos_1\"] = df_session[\"ratPos_1\"].astype(\"float64\")\n",
    "        df_session[\"ratPos_2\"] = df_session[\"ratPos_2\"].astype(\"float64\")\n",
    "\n",
    "        # Create subplot for this trial type\n",
    "        ax = plt.subplot(1, 3, i + 1)  # 1 row, 3 columns, current index\n",
    "\n",
    "        # Plot the laser's trajectory\n",
    "        ax.plot(df_session[\"laserPos_1\"], df_session[\"laserPos_2\"], color=\"blue\", linewidth=0.7, alpha=0.5, label=\"Laser Trajectory\", zorder=1)\n",
    "\n",
    "        # Plot the rat's trajectory\n",
    "        ax.plot(df_session[\"ratPos_1\"], df_session[\"ratPos_2\"], color=\"black\", linewidth=0.7, label=\"Rat Trajectory\", zorder=2)\n",
    "\n",
    "        # Mark start and end points\n",
    "        ax.scatter(df_session[\"ratPos_1\"].iloc[0], df_session[\"ratPos_2\"].iloc[0], color=\"green\", label=\"Start\", s=100, zorder=3)\n",
    "        ax.scatter(df_session[\"ratPos_1\"].iloc[-1], df_session[\"ratPos_2\"].iloc[-1], color=\"red\", label=\"End\", s=100, zorder=3)\n",
    "\n",
    "        ax.set_xlabel(\"X Position\")\n",
    "        ax.set_ylabel(\"Y Position\")\n",
    "        ax.set_title(f\"{trial_type} - Session {session_id}\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()  # Adjust spacing between subplots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute latency between rat position and target position \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Convert all halffloat columns to float64\n",
    "float_columns = [\"ratPos_1\", \"ratPos_2\", \"laserPos_1\", \"laserPos_2\"]\n",
    "df_session[float_columns] = df_session[float_columns].astype(\"float64\")\n",
    "\n",
    "def compute_latency(df_session, max_shift=60, step_size=2):\n",
    "    rat_pos = np.vstack((df_session[\"ratPos_1\"], df_session[\"ratPos_2\"])).T\n",
    "    target_pos = np.vstack((df_session[\"laserPos_1\"], df_session[\"laserPos_2\"])).T\n",
    "\n",
    "    max_corr = -1\n",
    "    optimal_shift = 0\n",
    "    shifts = np.arange(-max_shift, max_shift + 1, step_size)\n",
    "\n",
    "    print(\"\\nShift (ms) | Spearman Correlation\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    for shift in shifts:\n",
    "        if shift > 0:\n",
    "            shifted_rat = rat_pos[:-shift]\n",
    "            shifted_target = target_pos[shift:]\n",
    "        elif shift < 0:\n",
    "            shifted_rat = rat_pos[-shift:]\n",
    "            shifted_target = target_pos[:shift]\n",
    "        else:\n",
    "            shifted_rat = rat_pos\n",
    "            shifted_target = target_pos\n",
    "    \n",
    "        # Mask to remove NaNs before correlation\n",
    "        mask = ~np.isnan(shifted_rat).any(axis=1) & ~np.isnan(shifted_target).any(axis=1)\n",
    "        shifted_rat, shifted_target = shifted_rat[mask], shifted_target[mask]\n",
    "\n",
    "        # If arrays are empty after removing NaNs, continue to the next shift\n",
    "        if len(shifted_rat) == 0 or len(shifted_target) == 0:\n",
    "            print(f\"Skipping shift {shift * (1000 / 30):>9.0f} ms due to empty arrays.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Compute Spearman correlation\n",
    "        corr, _ = spearmanr(shifted_rat.ravel(), shifted_target.ravel())\n",
    "\n",
    "        print(f\"{shift * (1000 / 30):>9.0f} ms | {corr:.4f}\")\n",
    "\n",
    "        if corr > max_corr:\n",
    "            max_corr = corr\n",
    "            optimal_shift = shift\n",
    "\n",
    "    return optimal_shift * (1000 / 30)\n",
    " # Convert from samples to milliseconds\n",
    "\n",
    "#TODO: make this dynamic for all sessions\n",
    "# Example usage for a session\n",
    "session_id = df[\"sessFile\"].unique()[1]  # Select a session\n",
    "df_session = df[(df[\"trial_type\"] == \"RT\")].copy()  # Only RT trials\n",
    "\n",
    "latency = compute_latency(df_session)\n",
    "print(f\"Optimal Latency: {latency:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmaps of neurons by session\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "### 1️⃣ LOAD & FILTER YOUR DATA ###\n",
    "# 🛠 EDIT: Ensure your dataset has the required columns\n",
    "df = all_regions_data[(all_regions_data[\"region\"] == \"CA3\") & (all_regions_data[\"trial_block\"] == \"pursuit\")].copy()\n",
    "\n",
    "# 🛠 EDIT: Ensure necessary columns exist\n",
    "if \"time\" not in df.columns or \"trial_block\" not in df.columns or \"region\" not in df.columns:\n",
    "    raise ValueError(\"Dataset must have 'time', 'trial_block', and 'region' columns!\")\n",
    "\n",
    "# 🛠 EDIT: Detect spike table columns automatically\n",
    "spike_columns = [col for col in df.columns if \"spkTable\" in col]\n",
    "\n",
    "### 2️⃣ NORMALIZE TIME PER SESSION ###\n",
    "# Ensure sessFile is treated as a category to avoid issues\n",
    "df[\"sessFile\"] = df[\"sessFile\"].astype(\"category\")\n",
    "\n",
    "# Compute start time per session and normalize time\n",
    "df[\"time\"] = df[\"time\"].astype(\"float64\")  # Convert time to float64\n",
    "df[\"start_time\"] = df.groupby(\"sessFile\")[\"time\"].transform(\"min\")\n",
    "df[\"normalized_time\"] = df[\"time\"] - df[\"start_time\"]\n",
    "\n",
    "\n",
    "# 🛠 EDIT: If time is in milliseconds, divide by 1000 before normalization\n",
    "# df[\"normalized_time\"] = (df[\"time\"] / 1000) - df.groupby(\"sessFile\")[\"time\"].transform(\"min\")\n",
    "\n",
    "### 3️⃣ CREATE TIME BINS (16.67s) ###\n",
    "bin_width = 16.67  # Time bin size in seconds\n",
    "df[\"time_bin\"] = (df[\"normalized_time\"] // bin_width).astype(int)\n",
    "df[\"time_seconds\"] = df[\"time_bin\"] * (16.67 / 60)\n",
    "\n",
    "### 4️⃣ AGGREGATE SPIKE COUNTS PER TIME BIN ###\n",
    "# Convert spike data to integers, replacing NaNs with 0\n",
    "df[spike_columns] = df[spike_columns].fillna(0).astype(int)\n",
    "\n",
    "# Group by \"sessFile\" and \"time_bin\" to avoid mixing sessions\n",
    "df_binned = df.groupby([\"sessFile\", \"time_bin\"])[spike_columns].sum()\n",
    "df_binned = df_binned.reset_index()  # Reset index to keep 'time_bin'\n",
    "df_binned[\"time_seconds\"] = df_binned[\"time_bin\"] * (16.67 / 60)  # Convert to seconds\n",
    "df_binned = df_binned.set_index([\"sessFile\", \"time_seconds\"])  # Re-index using seconds\n",
    "\n",
    "### 5️⃣ APPLY Z-SCORE NORMALIZATION PER NEURON, PER SESSION ###\n",
    "# Ensure z-score works even if variance is 0\n",
    "df_zscored = df_binned.groupby(\"sessFile\").apply(lambda x: x.apply(lambda col: zscore(col, nan_policy=\"omit\") if col.std() > 0 else col, axis=0))\n",
    "\n",
    "# Verify results\n",
    "print(df_zscored.head())\n",
    "\n",
    "### 6️⃣ PLOT HEATMAP FOR EACH SESSION ###\n",
    "for session in df[\"sessFile\"].unique():\n",
    "    session_data = df_zscored.loc[session]  # Get session-specific data\n",
    "\n",
    "    # Remove 'time_bin' if it exists\n",
    "    if \"time_bin\" in session_data.columns:\n",
    "        session_data = session_data.drop(columns=[\"time_bin\"])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(session_data.T, cmap=\"coolwarm\", center=0, cbar=True, xticklabels=10)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Neurons\")\n",
    "    plt.title(f\"Z-Scored Neural Spike Activity - Session {session}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### 7️⃣ OPTIONAL: RASTER PLOT (SPIKES OVER TIME) ###\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for neuron in spike_columns:\n",
    "    neuron_data = df[df[neuron] > 0]  # Get rows where spikes occurred\n",
    "    plt.scatter(neuron_data[\"time_seconds\"], np.full(len(neuron_data), neuron), s=2, color=\"black\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")  # Updated label\n",
    "plt.ylabel(\"Neurons\")\n",
    "plt.title(\"Spike Raster Plot\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#define the start and end indices\n",
    "pursuit_start = (indices[\"pursuit_start\"].values[0])\n",
    "pursuit_end = (indices[\"pursuit_end\"].values[0])\n",
    "FE1_start = (indices[\"FE1_start\"].values[0])\n",
    "FE1_end = (indices[\"FE1_end\"].values[0])\n",
    "FE2_start = (indices[\"FE2_start\"].values[0])\n",
    "FE2_end = (indices[\"FE2_end\"].values[0])\n",
    "\n",
    "#get dataframe length\n",
    "max_rows = len(pursuit_df['KB20_09_pursuitRoot.mat'])\n",
    "\n",
    "#call get_block_rows() before slicing\n",
    "FE1_start, FE1_end = pursuit_functions.index_utils.get_block_rows(FE1_start, FE1_end, max_rows)\n",
    "pursuit_start, pursuit_end = pursuit_functions.index_utils.get_block_rows(pursuit_start, pursuit_end, max_rows)\n",
    "FE2_start, FE2_end = pursuit_functions.index_utils.get_block_rows(FE2_start, FE2_end, max_rows)\n",
    "\n",
    "#slice the data rows into trial blocks (FE= free explore)\n",
    "FE1_block = pursuit_df['KB20_09_pursuitRoot.mat'].iloc[FE1_start:FE1_end +1]if FE1_start is not None else None\n",
    "pursuit_block = pursuit_df['KB20_09_pursuitRoot.mat'].iloc[pursuit_start:pursuit_end +1] if pursuit_start is not None else None\n",
    "FE2_block = pursuit_df['KB20_09_pursuitRoot.mat'].iloc[FE2_start:FE2_end +1] if FE2_start is not None else None\n",
    "\n",
    "print(\"\\ncheck out the blocks\")\n",
    "print(pursuit_block)\n",
    "print(FE1_block)\n",
    "print(FE2_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = pursuit_block[\"ratPos_1\"]\n",
    "y = pursuit_block[\"ratPos_2\"]\n",
    "\n",
    "x_center = (x.max() + x.min()) / 2\n",
    "y_center = (y.max() + y.min()) / 2\n",
    "\n",
    "x_range = (x.max() - x.min()) / 2\n",
    "y_range = (y.max() - y.min()) / 2\n",
    "limit = max(x_range, y_range)  # Use max range to keep aspect equal\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.scatter(x, y, c='blue', label=\"Points\", s=0.05)\n",
    "\n",
    "ax.set_xlim([x_center - limit, x_center + limit])\n",
    "ax.set_ylim([y_center -limit, y_center +limit])\n",
    "\n",
    "ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "ax.axhline(y_center, color=\"gray\", linewidth=1)\n",
    "ax.axvline(x_center, color=\"gray\", linewidth=1)\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "ax.set_xlabel(\"X Coordinate\")\n",
    "ax.set_ylabel(\"Y Coordinate\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pursuit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
