{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages and functions\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pursuit_functions as pursuit\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data set\n",
    "\n",
    "all_pursuit_tasks = pd.read_parquet(\"ca1_ca3_rsc_pursuit_data.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NA values for RSC, CA1, and CA3 sessions\n",
    "RSC_sessions = all_pursuit_tasks[all_pursuit_tasks[\"region\"] == \"RSC\"]\n",
    "CA1_sessions = all_pursuit_tasks[all_pursuit_tasks[\"region\"] == \"CA1\"]\n",
    "CA3_sessions = all_pursuit_tasks[all_pursuit_tasks[\"region\"] == \"CA3\"]\n",
    "\n",
    "RSC_cleaned = pursuit.tuning.drop_NA_vals(RSC_sessions)\n",
    "CA1_cleaned = pursuit.tuning.drop_NA_vals(CA1_sessions)\n",
    "CA3_cleaned = pursuit.tuning.drop_NA_vals(CA3_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all coordinate values below 99th percentile and normalize points for all regions \n",
    "\n",
    "normalized_sessions = pursuit.tuning.normalize_points(all_pursuit_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the mean center and overall radius of the arena for all normalized data points\n",
    "#you can specify the percentile value to be considered for the overall radius; default is 95th percentile\n",
    "#calculates the individual center point for each session\n",
    "\n",
    "circle_boundaries, radius = pursuit.tuning.fit_circle_bounds(normalized_sessions)\n",
    "print(radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find circumference points for plotting using the center coordinates and overall radius\n",
    "all_circ_points = pursuit.tuning.circumference(circle_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot normalized concatenated laser and rat paths with center point and boundary\n",
    "#the function takes the normalized_sessions, circle_boundaries, and all_circ_points dataframes\n",
    "\n",
    "pursuit.tuning.plot_arena_bounds(normalized_sessions, circle_boundaries, all_circ_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize only laser points and make a dataframe containing spike data using the normalized data mask\n",
    "#function takes the cleaned df\n",
    "RSC_laser_spks = pursuit.tuning.norm_laser_get_spks(RSC_cleaned)\n",
    "CA1_laser_spks = pursuit.tuning.norm_laser_get_spks(CA1_cleaned)\n",
    "CA3_laser_spks = pursuit.tuning.norm_laser_get_spks(CA3_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSC_laser_spks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find distance of normalized laser points to circle boundary by each session\n",
    "#function takes the normalized laser/spikes and circle boundaries dataframes\n",
    "\n",
    "RSC_laser_spks_bounds = pursuit.tuning.dist_to_bounds(RSC_laser_spks, circle_boundaries)\n",
    "CA1_laser_spks_bounds = pursuit.tuning.dist_to_bounds(CA1_laser_spks, circle_boundaries)\n",
    "CA3_laser_spks_bounds = pursuit.tuning.dist_to_bounds(CA3_laser_spks, circle_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSC_laser_spks_bounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put raw spike counts into bins calculated from the overall min and max bound_dist values\n",
    "def bin_spike_data(dataframe, spk_prefix=\"spkTable\", num_bins=20, bin_edges=None):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = pursuit.tuning.find_bin_edges(dataframe, \"bound_dist\", num_bins)\n",
    "\n",
    "    for sessFile in dataframe[\"sessFile\"].unique():\n",
    "\n",
    "        session = dataframe[dataframe[\"sessFile\"] == sessFile].copy()\n",
    "\n",
    "        session[\"bound_bin\"] = pd.cut(session[\"bound_dist\"], bins=bin_edges, include_lowest=True)\n",
    "\n",
    "        spk_cols = [col for col in session.columns if spk_prefix in col and not session[col].isna().all()]\n",
    "\n",
    "        for spk in spk_cols:\n",
    "            spk_by_bin = session.groupby(\"bound_bin\")[spk].sum()\n",
    "\n",
    "            bin_midpoints = pd.IntervalIndex.from_breaks(bin_edges).to_series().apply(\n",
    "                lambda interval: round((interval.left + interval.right) / 2, 2)\n",
    "                )\n",
    "\n",
    "            for bin_mid, spk_count in zip(bin_midpoints, spk_by_bin):\n",
    "                rows.append({\n",
    "                    \"sessFile\": sessFile,\n",
    "                    \"neuron\": spk,\n",
    "                    \"spike_count\": spk_count,\n",
    "                    \"bin_midpoint\": bin_mid        \n",
    "                })\n",
    "\n",
    "    binned_spks_df = pd.DataFrame(rows)\n",
    "    return binned_spks_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put laser coordinates into bins calculated from the overall min and max bound_dist values\n",
    "def bin_laser_data(dataframe, num_bins=20, bin_edges=None):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = find_overall_bin_edges(dataframe, \"bound_dist\", num_bins)\n",
    "\n",
    "    for sessFile in dataframe[\"sessFile\"].unique():\n",
    "\n",
    "        session = dataframe[dataframe[\"sessFile\"] == sessFile].copy()\n",
    "\n",
    "        session[\"bound_bin\"] = pd.cut(session[\"bound_dist\"], bins=bin_edges, include_lowest=True)\n",
    "\n",
    "        coords_by_bin = session.groupby([\"bound_bin\"], observed=False).size()\n",
    "\n",
    "        for bin_interval, laser_count in coords_by_bin.items():\n",
    "            bin_mid = round((bin_interval.left + bin_interval.right) / 2, 2)\n",
    "            \n",
    "            rows.append({\n",
    "                    \"sessFile\": sessFile,\n",
    "                    \"laser_occupancy\": laser_count,\n",
    "                    \"bin_midpoint\": bin_mid\n",
    "                })\n",
    "\n",
    "    binned_laser_df = pd.DataFrame(rows)\n",
    "    return binned_laser_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the data!\n",
    "\n",
    "RSC_laser_binned = bin_laser_data(RSC_sessions_laser_bounds_spks)\n",
    "CA1_laser_binned = bin_laser_data(CA1_sessions_laser_bounds_spks)\n",
    "CA3_laser_binned = bin_laser_data(CA3_sessions_laser_bounds_spks)\n",
    "\n",
    "RSC_spikes_binned = bin_spike_data(RSC_sessions_laser_bounds_spks)\n",
    "CA1_spikes_binned = bin_spike_data(CA1_sessions_laser_bounds_spks)\n",
    "CA3_spikes_binned = bin_spike_data(CA3_sessions_laser_bounds_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize spike counts by laser occupancy using bins calculated from the overall min and max bound_dist values \n",
    "\n",
    "def make_tuning_curve(spike_df, laser_df):\n",
    "\n",
    "    merged_df = pd.merge(spike_df, laser_df, on=[\"sessFile\", \"bin_midpoint\"], how=\"left\")\n",
    "\n",
    "    merged_df[\"tuning\"] = merged_df[\"spike_count\"] / merged_df[\"laser_occupancy\"]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSC_binned_tuning = make_tuning_curve(RSC_spikes_binned, RSC_laser_binned)\n",
    "CA1_binned_tuning = make_tuning_curve(CA1_spikes_binned, CA1_laser_binned)\n",
    "CA3_binned_tuning = make_tuning_curve(CA3_spikes_binned, CA3_laser_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tuning_curves(dataframe):\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    for sessFile in dataframe[\"sessFile\"].unique():\n",
    "\n",
    "        session = dataframe[dataframe[\"sessFile\"] == sessFile]\n",
    "        \n",
    "        pivoted = (session.pivot(index=\"neuron\", columns=\"bin_midpoint\", values=\"tuning\").fillna(0))\n",
    "\n",
    "        for neuron in pivoted.index:\n",
    "            plt.plot(pivoted.columns, pivoted.loc[neuron], marker='o', linestyle='-', label=f\"{neuron}\")\n",
    "\n",
    "    plt.xlabel(\"Boundary Distance (bin midpoint)\")\n",
    "    plt.ylabel(\"Tuning (spike count / laser occupancy)\")\n",
    "    plt.title(f\"All Neuron Tuning Curves\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tuning_curves(RSC_binned_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSC_binned_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score binned normalized data\n",
    "\n",
    "def z_score_norm(dataframe):\n",
    "    \n",
    "    sessions = dataframe.copy()\n",
    "        \n",
    "    def norm_z(x):\n",
    "        std = x.std()\n",
    "        mean = x.mean()\n",
    "        z = (x - mean) / std if std > 0 else x*0\n",
    "\n",
    "        z_min, z_max = z.min(), z.max()\n",
    "        if z_max > z_min:\n",
    "            return (z - z_min) / (z_max - z_min)\n",
    "        else:\n",
    "            return z * 0\n",
    "\n",
    "        \n",
    "    sessions[\"z_score\"] = (\n",
    "        sessions.groupby([\"sessFile\", \"neuron\"])[\"tuning\"].transform(norm_z)\n",
    "    )\n",
    "\n",
    "    return sessions\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSC_z_scored = z_score_norm(RSC_binned_tuning)\n",
    "CA1_z_scored = z_score_norm(CA1_binned_tuning)\n",
    "CA3_z_scored = z_score_norm(CA3_binned_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap for z-scored data: RSC sessions\n",
    "\n",
    "pivoted_binned_zscore_neurons = RSC_z_scored.pivot_table(\n",
    "    index=[\"sessFile\", \"neuron\"], \n",
    "    columns=\"bin_midpoint\", \n",
    "    values=\"z_score\"\n",
    "    ).fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "heatmap = sns.heatmap(pivoted_binned_zscore_neurons, cmap=\"viridis\", annot=False, fmt=\".2f\", yticklabels=False)\n",
    "\n",
    "x_labels = heatmap.get_xticklabels()\n",
    "\n",
    "rounded_labels = [f\"{float(label.get_text()):.2f}\" if label.get_text() != \"\" else \"\" for label in x_labels]\n",
    "\n",
    "heatmap.set_xticklabels(rounded_labels, rotation=45, ha=\"right\")\n",
    "\n",
    "\n",
    "plt.title(f\"Z-scored Spike Activity by Boundary Distance: RSC Sessions\")\n",
    "plt.xlabel(\"Boundary Distance (bin midpoint)\")\n",
    "plt.ylabel(\"Neurons\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table and apply gaussian smoothing for plotting\n",
    "\n",
    "def pivot_smooth(dataframe, window_size=3, window_type='gaussian', std=1):\n",
    "\n",
    "    pivoted_df = dataframe.pivot_table(\n",
    "        index=[\"sessFile\", \"neuron\"], \n",
    "        columns=\"bin_midpoint\", \n",
    "        values=\"z_score\"\n",
    "        ).fillna(0)\n",
    "\n",
    "    smoothed_df = pivoted_df.apply(\n",
    "        lambda row: row.rolling(\n",
    "            window=window_size, \n",
    "            win_type=window_type, \n",
    "            center=True).mean(std=std), \n",
    "            axis=1\n",
    "        ).fillna(0)\n",
    "    \n",
    "    return smoothed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap for z-scored data\n",
    "\n",
    "def heatmap(dataframe):\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    heatmap = sns.heatmap(dataframe, cmap=\"viridis\", annot=False, fmt=\".2f\", yticklabels=False)\n",
    "\n",
    "    x_labels = heatmap.get_xticklabels()\n",
    "\n",
    "    rounded_labels = [f\"{float(label.get_text()):.2f}\" if label.get_text() != \"\" else \"\" for label in x_labels]\n",
    "\n",
    "    heatmap.set_xticklabels(rounded_labels, rotation=45, ha=\"right\")\n",
    "\n",
    "\n",
    "    plt.title(f\"Z-scored Spike Activity by Boundary Distance\")\n",
    "    plt.xlabel(\"Boundary Distance (bin midpoint)\")\n",
    "    plt.ylabel(\"Neurons\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmaps for z-scored data: CA3 Sessions\n",
    "\n",
    "pivoted_binned_zscore_neurons = CA3_z_scored.pivot_table(\n",
    "    index=[\"sessFile\", \"neuron\"], \n",
    "    columns=\"bin_midpoint\", \n",
    "    values=\"z_score\"\n",
    "    ).fillna(0)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "heatmap = sns.heatmap(pivoted_binned_zscore_neurons, cmap=\"viridis\", annot=False, fmt=\".2f\", yticklabels=False)\n",
    "\n",
    "x_labels = heatmap.get_xticklabels()\n",
    "\n",
    "rounded_labels = [f\"{float(label.get_text()):.2f}\" if label.get_text() != \"\" else \"\" for label in x_labels]\n",
    "\n",
    "heatmap.set_xticklabels(rounded_labels, rotation=45, ha=\"right\")\n",
    "\n",
    "\n",
    "plt.title(f\"Z-scored Spike Activity by Boundary Distance: CA3 Sessions\")\n",
    "plt.xlabel(\"Boundary Distance (bin midpoint)\")\n",
    "plt.ylabel(\"Neurons\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of neurons by sessFile and region dataframe\n",
    "\n",
    "def count_neurons(dataframe, spk_prefix=\"spkTable\"):\n",
    "\n",
    "    # Create an empty dictionary to hold the counts for each session.\n",
    "    session_neuron_counts = {}\n",
    "\n",
    "    # Iterate over unique sessions.\n",
    "    for sess in dataframe[\"sessFile\"].unique():\n",
    "        # Select only rows for that session.\n",
    "        session = dataframe[dataframe[\"sessFile\"] == sess]\n",
    "        \n",
    "        # Identify spkTable columns that are not entirely NaN for this session.\n",
    "        spk_cols = [col for col in session.columns \n",
    "                    if col.startswith(spk_prefix) and not sess_df[col].isna().all()\n",
    "        ]\n",
    "        \n",
    "        # Store the count for this session.\n",
    "        session_neuron_counts[sess] = len(spk_cols)\n",
    "\n",
    "    # Sum the counts over all sessions\n",
    "    total_neurons = sum(session_neuron_counts.values())\n",
    "\n",
    "    return session_neuron_counts, total_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pursuit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
